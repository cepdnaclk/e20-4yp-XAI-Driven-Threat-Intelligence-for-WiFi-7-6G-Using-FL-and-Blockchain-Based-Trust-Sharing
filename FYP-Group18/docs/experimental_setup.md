# Experimental Setup

## Hardware Environment
- Server-based Linux environment
- Multi-core CPU
- Sufficient memory for parallel client simulations

## Software Stack
- Python 3.x
- PyTorch / TensorFlow (model training)
- Federated learning framework
- Custom LiteChain blockchain modules

## Training Configuration
- Fixed number of communication rounds
- Identical model architectures across baselines
- Same dataset splits for fair comparison

## Baselines
1. Centralized learning
2. Standard federated learning (FedAvg)
3. LiteChain-based BCFL

## Evaluation Metrics
- Communication overhead
- End-to-end latency
- Convergence Speed
- Consensus Security Score
- On-chain storage
- Precision
- Recall
- F1-score

